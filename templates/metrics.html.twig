{% extends "base.html.twig" %}

{% block title %}About{% endblock %}

{% block body %}
    <h2>Introduktion</h2>
    <p>
        <h4>Codestyle</h4>
        Codestyle refererar till hur pass stora klasser och funktioner. Dvs hur långa klasser/funktioner är
        när man räknar antal rader kod. Stora klasser och metoder kan innebära att koden bli mer svårhanterad,
        det kan t.ex. bli svårare om behöver göra ändringar i den. Det kan även innebära svårigheter att vidareutveckla koden 
        om baskoden är väldigt lång.

        <h4>Coverage</h4>
        Kodtäckning är ett mått på hur väl koden som används är täckt av olika tester. Detta innebär i praktiken hur 
        stor del av de funktioner som används som det finns tillhörande tester till, och i sin tur och hur stor del av 
        respektive funktion som testerna täcker. Hög kodtäckning innebär att stora delar av koden är testad vilket i sin tur 
        innebär ökad trygghet att koden producerar önskat resultat. Låg kodtäckning innebär att det finns en hög risk att 
        koden kan producera fel resultat, eller att eventuella buggar eller dylikt kan uppstå.

        <h4>Complexity</h4>
        Desto högre komplexitets-score koden har ju svårare kan det bli att underhålla koden alternativ innebära problem om man skulle 
        behöva vidareutveckla den. 

        <h4>Cohesion</h4>
        Hänvisar till hur väl metoder i klasser här ihop med varandra. Ett lågt värde innebär hög sammanhållning, dvs att metoderna 
        verkligen hör hemma i klassen. Ett högt värde däremot innebär en låg sammanhållning, det betyder att en klass skulle kunna ha 
        delats upp i flera olika klasser med olika ansvarsområden.

        <h4>Coupling</h4>
        Coupling är indelat i två kategorier, den första är Afferent coupling (AC). AC är ett mått på antalet klasser som påverkas av en 
        viss klass. Hög AC innebär att klassen i fråga använder sig av många andra klasser inuti sig själv.
        Den andra är Efferent coupling (EC). EC är ett mått på antalet klasser som en specifik klass får funktionalitet/effekter från.
        Hög EC innebär att många andra klasser är beroende och/eller använder sig av funktioner från denna klassen.

        <h4>CRAP</h4>
        Change Risk Analyzer and Predictor beror på två olika variabler. Den ena är hur pass komplex din kod är medan den ändra är hur pass 
        vältestad koden är. Har man hög komplexitet kan man ha många tester för att balansera ut CRAP-poängen. 


    </p><br>



    <h2>Phpmetrics</h2>
    <img src="{{ asset('img/phpmetrics.png') }}" alt="" width="1000x"><br>
    <p>
        I koden finns det 6 stycken violations vilket skulle kunna anses som en förbättringspotential. Det som phpmetrics säger om 
        dessa violations är framförallt att det saknas tester på klasser för controller-klasserna. Anledningen till detta är att det inte har 
        skapats några tester för dessa klasser, eftersom att det inte har varit del av tidigare kursmoment och samt inte varit del av någon föreläsning.
    </p>

    <p>
        Den genomsnittliga komplexiteten för koden är låg vilket tyder på kod som är enkel att ändra och vidareutveckla. Dock så råkar 
        Game21-klassen hamna desto högre up på skalan i förhållande till de övriga klasser, så detta skulle kunna vara ett ställe där man skulle 
        kunna se över om det gick att förenkla komplexiteten för att på så sätt undvika framtida problem.
    </p>

    <p>
        Trots att den genomsnittliga komplexiteten är relativt låg så får koden ett något högt CRAP-score. Förklaringen till detta samt en eventuell 
        lösning är att testerna enbart täcker de klasser som innehåller funktioner som används i övriga Controller-klasser. I de klasserna är 
        kodtäckningen 100% vilket är bra, men i de övriga Controller-klasserna saknas det tester vilket därför resulterar i ett onödigt högt 
        CRAP-score.
    </p>

    <p>
        Koden har ett lågt genomsnittligt LCOM-värde. Detta innebär att den koden som finns har stor sammanhållning vilket i sin tur innebär 
        att funktioner/metoder ligger på rätt ställe i förhållande till klass och användningsområde/syfte. Detta trots att tidigare kursmoment krävt 
        att koden skulle delas upp i olika klasser för att uppnå arv mm. Frågan är om man kanske kunde uppnåt ett ytterligare lägre LCOM-värde om 
        de delar som från början var tänkta att ligga i en och samma klass då de ansågs höra ihop hade fått stanna kvar i sin ursprungliga klass?
    </p>

    <h2>Scrutinizer</h2>
    <p>
        I Scrutinizer fick hade koden som utgångspunkt 6,93 i Scrutinizer-betyg. Anledningen till detta var att mappen "tools" togs med 
        i testet vilket drog ner betyget. Detta var dock allt annat än självklart vid testandets början vilket ledde till att de filerna 
        som var relaterade till det nyss skrivna kursmomentet redigerades undertiden som den mappen fanns med. Dock så gjorde förbättringarna av 
        poängterade svagheter i de klasser något utslag på själva Scrutinizer-betyget. När tools-mappen sedan togs bort från testet 
        (då den inte skulle funnits med från början) ökade Scrutinizer-betyget till 9.82. Detta Scrutinizer-betyget representerar kvaliteten på koden 
        vilket i detta fall skulle innebära väldigt hög kvalitet då högsta tänkbara värde är 10.0.
    </p>
    <p>
        Det som Scrutinizer-testet klagade mest på var Coverage vilket enbart nådde upp till 13%. Dock så var anledningen till detta att det enbart 
        utförts test på de klasser som innehåller funktioner för att köra programmet. I dessa klasser uppgick kodtäckningen till 100%, men i övriga 
        klasser som innehöll routerna saknades tester. Då testandet av router inte har ingått i något tidigare kursmoment eller föreläsning utgick 
        därför detta. Däremot eftersom att kodtäckningen var 100% på de klasser där samtliga använda funktioner ingick kan man tycka att detta bör 
        vara tillräckligt för att vara säker på att de funktioner som används i routerna och i programmets helhet är vältestade och säkra att använda.  
    </p>
    <p>
        Det som kan ifrågasättas vid testandet är varför Scrutinizer fick ett så pass mycket sämre betyg när de php-delar som fanns med i tools-mappen var inkluderade. 
        Detta borde vara välskriven kod då den ska fungera för att köra andras kod och dessutom ge dem olika betyg på hur pass välskriven deras kod 
        är samt vilka förbättringsmöjligheter som finns. Tog man dock bort dessa delar kod vars uppgift var att utvärdera andras egenskrivna PHP-kod så ökade Scrutinizer-betyget. 
        Har detta att göra med hur eller vad det är som Scrutinizer testar? Kanske har olika sorters kod även olika möjlighet att 
        uppnå ett högt Scrutinizer-betyg beroende på vad kodens syfte är?
    </p>
        <a href="https://scrutinizer-ci.com/g/A-Norre/MVC_report/"><img src="{{ asset('img/scrut.png') }}" alt="" width="100x"></a><br>
        <a href="https://scrutinizer-ci.com/g/A-Norre/MVC_report/code-structure/main/code-coverage/src/"><img src="{{ asset('img/coverage.png') }}" alt="" width="100x"></a><br>
        <a href="https://scrutinizer-ci.com/g/A-Norre/MVC_report/inspections/a99afcb4-8535-4292-8a86-5bed241a1a7f/log"><img src="{{ asset('img/build.png') }}" alt="" width="100x" height="18px"></a><br>



    <h2>Förbättringar</h2>
        <p>
            De förbättringar som förväntas undersökas är de olika issues/violations som dyker upp i phpmetrics för att se över om det går 
            att åtgärda något eller några av dessa. I dagsläget påpekar den buggar, dock så är den genomsnittliga mängden buggar väldigt låg, det finns 
            dock ett error med då den klagar på något vilket hade varit bra att kunna åtgärda.
        </p>

        <p>
            En ytterligare förbättringsmöjlighet är komplexiteten i koden samt dess underhållningsmöjlighet. Det som utmärker sig är Game21-klassen 
            som har en röd cirkel vilket tyder på hög komplexitet samt dålig underhållningsmöjlighet, denna hade varit bra att försöka åtgärda något.
        </p>

        <p>
            Från början var Scrutinizers kvalitetsindex 6,93. Därefter justerades de påpekade felen som var relaterade till den egenskriva koden. 
            Dock så hade detta i dåläget ingen synlig påverkar på kvalitetsindexet, detta kan dock ha berott på att mängden kod då tools-mappen var 
            inkluderad var betydligt större, för när den togs bort så ökades kvalitetsindexet till 9,82 vilket inte lämnar speciellt stort utrymme till 
            förbättring men det hade ändå varit intressant att försöka förbättra den ytterligare om möjligt.
        </p>

        <h2>Efter implementerade förbättringar:</h2>

        <p>
            Värt att notera är tyvärr att det inte finns någon möjlighet att få tag på historik i phpmetrics då den uppdaterar alla värden varje gång 
            vilket gör det svårt att konkret redovisa resultat med före och efterbilder. Jag lyckades få bort en av de buggar som phpmetrics påpekade samt 
            att även felet (error) försvann. Det jag gjorde var att jag delade upp min ProductController till en ytterligare klass vid namn ProductControllerAPI 
            där samtliga API relaterade delar placerades. Det gjorde så att buggen samt felet försvann. Det bidrog dessutom även till att LCOM minskade från 2.49 
            till 1,8 vilket är ett lågt och bra värde.

            <br><img src="{{ asset('img/lcom.png') }}" alt="" width="200x">
        </p>

        <p>
            Jag lyckades även simplifiera Game21-klassen något, där jag i metoden totalScore lyckades rensa bort onödiga if-satser för att på så 
            sätt minska kodens komplexitet och förbättra kodens underhållningsmöjlighet. Istället för att kolla när banken vann så sätts banken som 
            default-vinnare. Skulle något av de övriga if-satserna stämma betyder det att spelaren har vunnit istället och då ändras "winner"-variabeln till "player". 
            På så sätt kunde färre antal if-satser användas då banken inte behövde några if-satser längre vilket bidrog till minskad komplexitet.
            Detta resulterade även till att klassen representerades av en 
            gul cirkel istället för en röd vilket tyder på ett positivt resultat. Det är dock så att den koden som finns är till för att räkna fram 
            poängen i ett relativt komplext poängsystem så det är svårt att få ner den ytterligare.

            <br><img src="{{ asset('img/game21.png') }}" alt="" width="500x"><br>
            <h5>Före:</h5>
            <img src="{{ asset('img/komplexitetold.png') }}" alt="" width="500x"><br>
            <h5>Efter:</h5>
            <img src="{{ asset('img/komplexitet.png') }}" alt="" width="400x"><br>
        </p>

        <p>
            I och med ovan nämnda förbättringar så innebar det att kvalitetsindexet ökade mer en sparsam mängd. Den gick från 9,82 till 9,83. Detta 
            är med tanke på den låga förbättringspotential som fanns kvar i kvalitetsindexet en bra procentuell ökning av kvarstående procent. Ökningen 
            beror troligtvis mest på att Game21-klassen förenklades vilket tyder på att kodkvaliteten också ökade i och med detta.

            <br><img src="{{ asset('img/scrut1.png') }}" alt="" width="200x">&nbsp&nbsp<img src="{{ asset('img/scrut2.png') }}" alt="" width="200x">

        </p>
    <br>

     <h2>Diskussion</h2>
    <p>
        Det går säkert att arbeta aktivt med kodkvalitet på detta sättet, frågan är vem som har definierat vad "clean code" är.
        Som exempel så ansåg scrutinizer att jag hade "död kod" när jag körde ett antal funktioner i rad på ett objekt för att 
        därefter mata in resultatet i en variabel som jag hade döpt till ett lämpligt namn för att förklara vad resultatet av funktioner var 
        och samtidigt vad variabeln innehöll, i detta fall "remaining cards". Enligt scrutinizer så var denna extra variabeln överflödig då 
        koden i nästa steg matade in variabeln i en sessionsvariabel. För att lösa anmärkningen så skippade jag mellanvariabeln och körde istället 
        hela kodraden med alla funktionerna rakt in i sessionen. Resultatet blev att det blev en rad kortare kod, omärkbar skillnad i hastighet men betydligt mer 
        svårlästkod. 
        <h5>Före:</h5>
        <img src="{{ asset('img/dirtycode.png') }}" alt="" width="500x">
        <h5>Efter:</h5>
        <img src="{{ asset('img/cleancode.png') }}" alt="" width="600x">
        <br>
    </p>
    <p>
        Enligt min mening så är Clean code något subjektivt. I olika personers ögon anses samma kod kanske inte som Clean code för samtliga. 
        Enligt scrutinizer så verkar det som att samtliga delar ska förkortas så långt det bara går. Man kan då fråga sig, var går gränsen? Och till 
        vilken nytta? Är det bara kort kod som man är ute efter bör man kanske i så fall även spara in på längden av variabelnamn. En annnan tanke är om det 
        är så att koden enbart ska gå fort att köra för att anses som Clean code så kan man t.ex göra om float-tal till 
        en mängd olika integers för att i slutändan när float-talet krävs göras om tillbaka till ett float-tal för att på så sätt spara mängden data 
        som koden behöver komma ihåg/läsa/flytta.
    </p>
    <p>
        Personligen så är Clean code enligt mig kod som är enkel att förstå och sätta sig in i. Ibland kanske det inte är optimalt för ett program 
        att all kod är nestlad till det maximala, utan istället dela upp koden på några ytterligare rader så att om man vid behov kan gå tillbaka och justera 
        något har det enklare att förstå vad som sker. Det kan ytterligare förenklas genom att välja beskrivande variabelnamn så att man enbart genom att 
        läsa kan förstå vad variabeln innehåller. Samma gäller funktioner och metoder, har man tydliga namn på dessa som beskriver vad som sker och eventuellt 
        även vad som returneras kan man undvika att behöva gå in i varenda funktion för att försöka förstå flödet. 
    </p>
    <p>
        I uppgiften vi precis har genomfört så fick jag en högt scrutinizer-betyg vilket verkar tyda på hög kvalitet på koden. Jag valde från början 
        medvetet att försöka hålla min kod och mitt program så sparsamt som möjligt och inte göra några överdrivna objekt eller överflödiga funktioner 
        för att lösa problemen. Resultatet av detta blev att jag fick ett högt betyg direkt när jag körde min kod. Trots att koden enbart nådde upp till 
        13% i coverage så berättar inte detta hela sanningen. De klasser som innehåller de funktioner som används i de olika Controller-klasserna har en 
        gemensam kodtäckning på 100%. Det betyder att alla funktioner som används är testade till 100% vilket också gick relativt smidigt då den 
        grundläggande koden var så pass "ren" som möjligt från början. Dock så tar inte scrutinizer hänsyn till vilken kod som används och till vad, 
        utan den förväntar sig att samtliga klasser bör ha test, så helhetsbetyget blev därför istället 13% när alla Controller-klasser tagits med i beräkningen.
    </p><br>
    
    
{% endblock %}
